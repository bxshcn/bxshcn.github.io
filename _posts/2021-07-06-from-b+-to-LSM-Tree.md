---
layout: post
title:  "从B+树到LSM树"
comments: true
categories: 数据库 
tags: B-tree,LSM-tree
---

## 读 vs 写
提升读和写磁盘的效率是数据库研究领域的一个核心问题。

对于写来说，顺序操作磁盘是一个关键考量因素：如果能实现顺序写，就能显著提高写性能。

对于读来说，提升读性能的方法有多种方法：
1. 批量访问，即一次读取一批数据。显然，批量读的前提是读取的数据本身具有相关性，这要在**写磁盘**的时候进行保证；或者该场景对批量读取的数据相关性不做要求。
2. 快速找到读数据的磁盘地址。这可以通过如下几种典型方法达成：
   - 有序数据，这样就可以通过二分查找快速定位所需数据。显然，数据的有序特性需要在写磁盘的时候进行保证。注意，数据的有序性本质上就是一种自索引机制。从这个角度说，有序数组，B+树都是一种有序数据。
   - 外部地址索引。比如典型的B树索引。hash当然也可以视为一种索引机制。

读和写相互依赖和影响：写的时候越保证顺序性和相关性，写的效率就越低；但读的数据越具有顺序性和相关性，则读的效率就越高，为了高的读效率往往会降低写的效率，而为了提高写的效率往往会牺牲读的效率。大多数情况下，这种冲突是内在固有的，我们只能在两者之间寻求一种平衡。
> 在一些特定场景下，读写的某些冲突会弱化甚至完全消失，人们因此而进行针对性优化，从而能同时得到更高的读写效率。比如：
> 1. 时序数据库，写的数据本身从时间角度天然是有序的
> 2. 消息中间件，写的数据本身从时间角度天然是有序的
> 3. 分布式缓存，完全在内存中操作，彻底消除了上述读写冲突。

## 高效读
传统的关系型数据库是写少读多的典型应用。

> 所谓写少读多只是相对而言：写相对于读更少，读相对于写更多，但在高负载写压力下，关系数据库的写I/O也很大。为了提高写的性能，常常采取缓存，配合WAL、no-force和steal机制来分散磁盘的I/O压力。相关内容可参考[持久化和WAL](https://bxshcn.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93/2021/06/09/duration-and-WAL.html)。

因为读的多，传统关系型数据库采用B+树来有序存放数据记录，B+树是一个存放在外部磁盘上的多叉平衡树，每个节点往往有数百个子节点，其层高一般<5，其叶子节点存放所有记录项，并形成一个有序链表。

除此之外，关系型数据库还使用外部索引机制来加快记录数据的地址定位，比如hash索引，或者B树索引。

## 高效写
上面提到的WAL（Write-Ahead-Log）是一种log，它是一种只在头部写的简单数据结构，我们把类似于log，只进行顺序追加写的数据结构，称为log-structured数据结构。

单纯的log-structured数据结构，可以直接应用在一些特定的场景中：
1. 上面提到的数据库的WAL。因为读场景只涉及顺序批量访问相关数据记录
2. Kafka中的消息读写。因为Kafka总是依据消息生产的顺序进行消费，根据消息编号计算偏移即可直接找到需要数据项的地址。

但更多的场景需要实施随机读，单纯的log-structured数据结构虽然可以提高写的效率，但无序的数据会显著降低读的效率。为平衡读的效率，人们对单纯的log-strucutred数据结构进行了两项关键改造：
1. 在写的时候，先在内存中进行实时排序（一般会使用skip-list或者red-black tree）之后，才批量写到数据文件中。
2. 对多个批量块数据文件进行有序合并（basic compact），即一旦某个既定大小块文件的数量达到一定值，则将其进行合并，比如每得到20个5M的文件，则将其进行合并，每得到5个100M的文件，则将其进行合并……
   > basic compact的问题是，随着时间的持续，单个块文件越来越大，一次性合并的内容越来越多，从而导致I/O出现瓶颈，为此人们又提出了levelled compaction，即不再根据块文件的数量进行合并，而是根据块文件所处的level进行合并：
   > 1. 每个level会有多个块文件，它们被作为一个整体进行管理：在一个level中查找某个数据项时，实际只需查找一个文件
   > 2. 当某个level满（每个level的文件数量是预先定义的）的时候，会从当前level中取出一个文件然后将其合并到更高一级的文件中，这样当前level就可以继续容纳添加更多的数据。
这就是LSM树（Log-structured Merge Tree），应用LSM树组织底层数据存储的典型应用比如LevelDB、Cassandra，influxDB也可归为此类。

为了进一步提高读的效率，人们又针对LSM树中的块数据文件进行优化，即在块数据文件的尾部：
1.	或者加入一个针对文件内chunks的indexed结构
2.	或者加入一个针对文件内chunks的[bloom filter结构](https://en.wikipedia.org/wiki/Bloom_filter)

这些为提升读效率而引入的数据结构，会增加了一些计算和随机的I/O写，从而影响写的效率。

## 结论
无论是B+树还是LSM树，都利用了数据的有序特性来保证读效率。B+树是全局有序，LSM树是局部有序，因此B+树的读效率更高。

在写效率上，LSM树充分利用了顺序写的特性，写效率更高。
> B+树的写似乎并没有利用顺序写的特性。传统关系型数据库只是顺序写WAL（比如Redo或者Undo，是日志而非真正的业务数据），作为一种缓冲机制来提高写效率，但在真正写业务数据（B+树和相关索引）的时候，还是随机的。


参考
- [1] stopford. [Log Structured Merge Trees](http://www.benstopford.com/2015/02/14/log-structured-merge-trees/)
- [2] O'Neil. The Log-Structured Merge-Tree (LSM-Tree). 1996
